{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd6b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#configure\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb86249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('G:/CS Year 4/1st Semester/Graduation/Test3/Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f101e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>studentAnswer</th>\n",
       "      <th>referenceAnswer</th>\n",
       "      <th>ref_1</th>\n",
       "      <th>ref_2</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>By letting it sit in a dish for a day.</td>\n",
       "      <td>The water was evaporated, leaving the salt.</td>\n",
       "      <td>We evaporated the salt from the water because ...</td>\n",
       "      <td>I put some water in a dish and let the water e...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Let the water evaporate and the salt is left b...</td>\n",
       "      <td>The water was evaporated, leaving the salt.</td>\n",
       "      <td>We evaporated the salt from the water because ...</td>\n",
       "      <td>I put some water in a dish and let the water e...</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The water evaporated and left salt crystals.</td>\n",
       "      <td>The water was evaporated, leaving the salt.</td>\n",
       "      <td>We evaporated the salt from the water because ...</td>\n",
       "      <td>I put some water in a dish and let the water e...</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I saw a pinkish grayish color that was blockin...</td>\n",
       "      <td>The water was evaporated, leaving the salt.</td>\n",
       "      <td>We evaporated the salt from the water because ...</td>\n",
       "      <td>I put some water in a dish and let the water e...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You have to slowly tip the vial for only the w...</td>\n",
       "      <td>The water was evaporated, leaving the salt.</td>\n",
       "      <td>We evaporated the salt from the water because ...</td>\n",
       "      <td>I put some water in a dish and let the water e...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      studentAnswer  \\\n",
       "0           0             By letting it sit in a dish for a day.   \n",
       "1           1  Let the water evaporate and the salt is left b...   \n",
       "2           2       The water evaporated and left salt crystals.   \n",
       "3           3  I saw a pinkish grayish color that was blockin...   \n",
       "4           4  You have to slowly tip the vial for only the w...   \n",
       "\n",
       "                               referenceAnswer  \\\n",
       "0  The water was evaporated, leaving the salt.   \n",
       "1  The water was evaporated, leaving the salt.   \n",
       "2  The water was evaporated, leaving the salt.   \n",
       "3  The water was evaporated, leaving the salt.   \n",
       "4  The water was evaporated, leaving the salt.   \n",
       "\n",
       "                                               ref_1  \\\n",
       "0  We evaporated the salt from the water because ...   \n",
       "1  We evaporated the salt from the water because ...   \n",
       "2  We evaporated the salt from the water because ...   \n",
       "3  We evaporated the salt from the water because ...   \n",
       "4  We evaporated the salt from the water because ...   \n",
       "\n",
       "                                               ref_2   accuracy  \n",
       "0  I put some water in a dish and let the water e...  incorrect  \n",
       "1  I put some water in a dish and let the water e...    correct  \n",
       "2  I put some water in a dish and let the water e...    correct  \n",
       "3  I put some water in a dish and let the water e...  incorrect  \n",
       "4  I put some water in a dish and let the water e...  incorrect  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddeb228",
   "metadata": {},
   "source": [
    "# DATA CLEANING & PRE-PROCESSING using Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff0af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(headline):\n",
    "  le=WordNetLemmatizer()\n",
    "  word_tokens=word_tokenize(headline)\n",
    "  tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "  cleaned_text=\" \".join(tokens)\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38691f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000) # to play with. min_df,max_df,max_features etc...\n",
    "vect_text=vect.fit_transform(df['studentAnswer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3814faac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4925, 1000)\n",
      "  (0, 198)\t0.4688001590192522\n",
      "  (0, 224)\t0.46496666479704374\n",
      "  (0, 765)\t0.526297034675938\n",
      "  (0, 459)\t0.5357647271166253\n",
      "  (1, 65)\t0.5135175067271285\n",
      "  (1, 452)\t0.412879040429809\n",
      "  (1, 708)\t0.33628185623130286\n",
      "  (1, 265)\t0.44536577453626647\n",
      "  (1, 963)\t0.25501185101989426\n",
      "  (1, 456)\t0.43515912507870236\n",
      "  (2, 189)\t0.42097114600507246\n",
      "  (2, 266)\t0.5865554299389977\n",
      "  (2, 452)\t0.4838560193369118\n",
      "  (2, 708)\t0.3940912092847385\n",
      "  (2, 963)\t0.29885028552133597\n",
      "  (3, 75)\t0.6075247506354002\n",
      "  (3, 148)\t0.45221552281229876\n",
      "  (3, 716)\t0.579132556094528\n",
      "  (3, 963)\t0.3016956757469561\n",
      "  (4, 347)\t0.40783233763618426\n",
      "  (4, 944)\t0.6156543672477247\n",
      "  (4, 773)\t0.5931106185423215\n",
      "  (4, 963)\t0.3207214970022335\n",
      "  (5, 881)\t0.39459954700616756\n",
      "  (5, 708)\t0.3328028517631009\n",
      "  :\t:\n",
      "  (4917, 278)\t0.5410981452801741\n",
      "  (4917, 154)\t0.5610504890380187\n",
      "  (4917, 580)\t0.3397920135260598\n",
      "  (4918, 154)\t0.5562283127941136\n",
      "  (4918, 233)\t0.7071402099613585\n",
      "  (4918, 177)\t0.4365349785550061\n",
      "  (4919, 258)\t0.6054055790040175\n",
      "  (4919, 278)\t0.5525194590904227\n",
      "  (4919, 154)\t0.5728929500676693\n",
      "  (4920, 813)\t0.5360545776783003\n",
      "  (4920, 289)\t0.473601776915029\n",
      "  (4920, 529)\t0.5619084114949064\n",
      "  (4920, 729)\t0.4154585222911394\n",
      "  (4921, 680)\t0.7370100712604619\n",
      "  (4921, 154)\t0.6758817610060571\n",
      "  (4922, 389)\t0.5326878375377421\n",
      "  (4922, 169)\t0.5426851672420802\n",
      "  (4922, 170)\t0.4684390494866419\n",
      "  (4922, 278)\t0.4497792057341593\n",
      "  (4923, 169)\t0.7699338822653743\n",
      "  (4923, 278)\t0.6381236690013691\n",
      "  (4924, 813)\t0.45398290551520165\n",
      "  (4924, 828)\t0.5631740510560972\n",
      "  (4924, 984)\t0.5888827989647383\n",
      "  (4924, 439)\t0.36048794543021206\n"
     ]
    }
   ],
   "source": [
    "print(vect_text.shape)\n",
    "print(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7fed213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18059c",
   "metadata": {},
   "source": [
    "# We can now see the most frequent and rare words in the students' answers on idf score. The lesser the value, more common is the word in the students' answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3dcd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01409174 -0.01137884 -0.01540341 ... -0.00039546  0.01060031\n",
      "   0.00041955]\n",
      " [ 0.15231533 -0.15867724 -0.22247695 ... -0.09520784  0.09716631\n",
      "   0.00505616]\n",
      " [ 0.18065488 -0.19972986 -0.26795988 ... -0.16045746  0.28025506\n",
      "   0.15343015]\n",
      " ...\n",
      " [ 0.03129362 -0.02742252  0.03947328 ...  0.0131192   0.00598386\n",
      "  -0.0010587 ]\n",
      " [ 0.02421383 -0.02486601  0.03506129 ...  0.01118825  0.01032264\n",
      "  -0.00382459]\n",
      " [ 0.05429792 -0.02582328  0.03419618 ... -0.0307217  -0.02342217\n",
      "   0.02496368]]\n",
      "(4925, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdcea17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Answer  0  :  1.4091741424342528\n",
      "Answer  1  :  -1.1378838636842505\n",
      "Answer  2  :  -1.5403406119532357\n",
      "Answer  3  :  -0.8190379919692595\n",
      "Answer  4  :  -0.17717802469807512\n",
      "Answer  5  :  0.015038967584978035\n",
      "Answer  6  :  -0.27221548599013196\n",
      "Answer  7  :  -0.039546056740992507\n",
      "Answer  8  :  1.060031283023906\n",
      "Answer  9  :  0.041954622736524665\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,answer in enumerate(l):\n",
    "  print(\"Answer \",i,\" : \",answer*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd07a92",
   "metadata": {},
   "source": [
    "# Now we can get a list of the important words for each of the 10 answers as shown. For simplicity here I have shown 10 words for each answer. \"Student Answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a681a4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 0: \n",
      "would one water pitch different sound make see string higher \n",
      "\n",
      "Answer 1: \n",
      "pitch would string higher lower sound high low make short \n",
      "\n",
      "Answer 2: \n",
      "one light motor run bulb circuit time work goes switch \n",
      "\n",
      "Answer 3: \n",
      "one sugar scratch see variable experiment pitch pure harder fat \n",
      "\n",
      "Answer 4: \n",
      "different sammy sound wood make sizes metal yes marbles nathaniel \n",
      "\n",
      "Answer 5: \n",
      "would sugar see pure cookies food know bubbles cream fruity \n",
      "\n",
      "Answer 6: \n",
      "sugar food string pure cookies sound cream fruity indicates make \n",
      "\n",
      "Answer 7: \n",
      "heat light sun time black goes sugar faster speed dark \n",
      "\n",
      "Answer 8: \n",
      "crystals salt light like string look different pitch goes time \n",
      "\n",
      "Answer 9: \n",
      "heat like crystals salt black look yes circuit make white \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Answer \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
