{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset.csv')\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data ['accuracy'] = label_encoder.fit_transform(data['accuracy'])\n",
    "student_answer = data['studentAnswer']\n",
    "ref_answers = data['referenceAnswer']\n",
    "ref_1= data['ref_1']\n",
    "ref_2= data['ref_2']\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "  out = word_tokenize(s)\n",
    "  ans = ' '.join([''.join(ps.stem(word)) for word in out if word not in stop_words])\n",
    "  return ans\n",
    "filtered_answers = [clean(s) for s in student_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_answers[0])\n",
    "print(student_answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "  out = word_tokenize(s)\n",
    "  ans = ' '.join([''.join(ps.stem(word)) for word in out if word not in stop_words])\n",
    "  return ans\n",
    "filtered_answers_ref2 = [clean(s) for s in ref_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_answers_ref2[0])\n",
    "print(ref_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers= filtered_answers+filtered_answers_ref2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=len(filtered_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = answers\n",
    "# print(test_sent)\n",
    "cv = TfidfVectorizer()\n",
    "tfidf = cv.fit_transform(test_sent)\n",
    "students_answers = tfidf[:l]\n",
    "model_answers = tfidf[l:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
